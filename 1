import numpy as np
import torch
from torch.utils import data
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter
import torch.optim as optim
import time
import scipy.io

samplesfile = scipy.io.loadmat('./dataset/A01T.mat')  # 读入字典
eegdata = samplesfile['data']
eegdata_train_1 = eegdata[0][7]['X'][0][0]
eegdata_trial_1 = eegdata[0][7]['trial'][0,0]
eegdata_target_1 = eegdata[0][7]['y'][0][0]
#print(eegdata_train_1.shape)
#print(eegdata1)

tbase = 0.2  # 基线长度
ttrial = 1.8  # 关注的脑电时间段
fs = 250  # 采样率

#[item.flat[0] for item in eegdata[0][0]['X']]
## train data
### epoch data将数据分段
epochdata_1 = np.zeros((48, 25, int((tbase + ttrial) * fs)))  # 初始化一个数组用于存放分段后的脑电数据
i = 0
for temp in epochdata_1:

    #print(round((eegdata2[i,0] - tbase) * fs) + int((tbase + ttrial) * fs))
    a = round(eegdata_trial_1[i,0])
    a = abs(a)
    # print('a',round(a))
    b = a + int((tbase + ttrial) * fs)
    #ar2 = [[row[i] for row in arr] for i in range(len(arr[0]))],二维数组行列互换
    eegdata_X1 = eegdata_train_1[a:b,:]
    eegdata_X1 = [[row[i] for row in eegdata_X1] for i in range(len(eegdata_X1[0]))]
    epochdata_1[i, :, :] = eegdata_X1
    i += 1
epochdata_1 = torch.FloatTensor(epochdata_1)  # 将分段后的数据转化为float类型，否则无法进行训练



## test data
eegdata_train_2 = eegdata[0][8]['X'][0][0]
eegdata_trial_2 = eegdata[0][8]['trial'][0,0]
eegdata_target_2 = eegdata[0][8]['y'][0][0]

epochdata_2 = np.zeros((48, 25, int((tbase + ttrial) * fs)))  # 初始化一个数组用于存放分段后的脑电数据
i = 0
for temp in epochdata_2:

    #print(round((eegdata2[i,0] - tbase) * fs) + int((tbase + ttrial) * fs))
    a = round(eegdata_trial_2[i,0])
    a = abs(a)
    # print('a',round(a))
    b = a + int((tbase + ttrial) * fs)
    #ar2 = [[row[i] for row in arr] for i in range(len(arr[0]))],二维数组行列互换
    eegdata_X2 = eegdata_train_2[a:b,:]
    eegdata_X2 = [[row[i] for row in eegdata_X2] for i in range(len(eegdata_X2[0]))]
    epochdata_2[i, :, :] = eegdata_X2
    i += 1
epochdata_2 = torch.FloatTensor(epochdata_2)  # 将分段后的数据转化为float类型，否则无法进行训练

print ('Training/Valid data shape: {}'.format(eegdata_train_1.shape))
print ('Test data shape: {}'.format(eegdata_train_2.shape))
print ('Training/Valid target shape: {}'.format(eegdata_target_1.shape))
print ('Test target shape: {}'.format(eegdata_target_2.shape))

### make labels做标签
#labels = np.zeros((20))  # 初始化标签数组
#labels = torch.LongTensor(eegdata[0][:,2])  # 标签需要转化为long类型，否则无法进行训练
#labels = torch.LongTensor(labels)
labels_1 = np.zeros(48)
labels_1 = torch.LongTensor(eegdata_target_1[:])
labels_1 = labels_1.squeeze()
labels_2 = np.zeros(48)
labels_2 = torch.LongTensor(eegdata_target_2[:])
labels_2 = labels_2.squeeze()

### make train data
train_data1 = data.TensorDataset(epochdata_1, labels_1)

### make test data
train_data2 = data.TensorDataset(epochdata_2, labels_2)
#Run this
batch_size = 128
valid_size = 0.2

# obtain training indices that will be used for validation
num_train = len(train_data1)
indices = list(range(num_train))
np.random.shuffle(indices)
split = int(np.floor(valid_size * num_train))
train_idx, valid_idx = indices[split:], indices[:split]

# define samplers for obtaining training and validation batches
train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)

# prepare data loaders (combine dataset and sampler)
train_loader = data.DataLoader(train_data1, batch_size=batch_size, sampler=train_sampler)
valid_loader = data.DataLoader(train_data1, batch_size=batch_size, sampler=valid_sampler)
test_loader = data.DataLoader(train_data2, batch_size=batch_size)


train_on_gpu = torch.cuda.is_available()

# check if CUDA is available
device = torch.device("cuda:0" if train_on_gpu else "cpu")
print(device)
if not train_on_gpu:
    print('Training on CPU ...')
else:
    print('Training on GPU ...')


class AlexNet(nn.Module):

    def __init__(self, num_classes=48):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv1d(25, 64, kernel_size=22, stride=2),
            nn.BatchNorm1d(64, affine=False),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool1d(kernel_size=12, stride=2),
            nn.Dropout(p=0.8),
            nn.Conv1d(64, 192, kernel_size=12),
            nn.BatchNorm1d(192, affine=False),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool1d(kernel_size=3, stride=2),
            nn.Dropout(p=0.8),
            nn.Conv1d(192, 384, kernel_size=4, stride=2),
            nn.BatchNorm1d(384, affine=False),
            nn.LeakyReLU(inplace=True),
            nn.Dropout(p=0.8),
            nn.Conv1d(384, 256, kernel_size=4, stride=2),
            nn.BatchNorm1d(256, affine=False),
            nn.LeakyReLU(inplace=True),
            nn.Dropout(p=0.8),
            nn.Conv1d(256, 256, kernel_size=4),
            nn.BatchNorm1d(256, affine=False),
            nn.LeakyReLU(inplace=True),
            nn.MaxPool1d(kernel_size=4, stride=1),

        )
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.BatchNorm1d(256 * 5),
            nn.LeakyReLU(inplace=True),
            nn.BatchNorm1d(256 * 5),
            nn.LeakyReLU(inplace=True),
            nn.Linear(256 * 5, num_classes),
        )

        self.classifier1 = nn.Sequential(
            nn.Dropout(),
            nn.BatchNorm1d(256 * 5),
            nn.Linear(256 * 5, 32),
            nn.ReLU(),
            nn.Dropout(),
            nn.Linear(32, 256 * 5),
            nn.ReLU(),
            nn.Dropout(),
            nn.Linear(256 * 5, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        y = torch.flatten(x, 1)
        x = self.classifier(y)
        x1 = self.classifier1(y)
        return x, x1


# create a complete CNN
model = AlexNet()

# move tensors to GPU if CUDA is available
if train_on_gpu:
    model.cuda()

writer = SummaryWriter('./tensorboard/cnn')


#Train the Model
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), weight_decay=0.0005, lr=1e-3)

valid_loss_min = np.Inf # track change in validation loss

# number of epochs to train the model
n_epochs = 200

t0 = time.time()

# 训练集中会自动进行归一化，测试集要手动归一化一哈(应该是在下边的代码中针对训练集和测试集的区别，所以需要这一步)
m = nn.LayerNorm([48, 25, 500])
#test_x = m(epochdata_2)
test_y = labels_2
print(test_y)


for epoch in range(1, n_epochs + 1):

    # keep track of training and validation loss
    train_loss = 0.0
    valid_loss = 0.0

    ###################
    # train the model #
    ###################
    model.train()
    for data, target in train_loader:
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        optimizer.zero_grad()
        output, output1 = model(data)
        #print(output1[0])
        #print(target[0])
        loss = criterion(output, target)
        # print(target.data)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * data.size(0)

    ######################
    # validate the model #
    ######################
    test_x = np.zeros((48, 9))  # 初始化一个数组用于存放分段后的脑电数据
    model.eval()
    for data, target in valid_loader:
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        output, output1 = model(data)
        loss = criterion(output, target)
        '''
        for temp in output:
          test = output[:,:]
          test = [[row[i] for row in test] for i in range(len(test[0]))]
          print(test)
          test_x[i,:] = test
          i += 1
        '''

        output = [[row[i] for row in output] for i in range(len(output[0]))]
        output = np.array(output)  # list转numpy.array
        output = output.astype(float)  # numpy强制类型转换
        output = torch.from_numpy(output)  # array to tensor
        output = output.cpu()
        pred_y = torch.max(output, 1)[1].data.numpy()

        accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))
        valid_loss += loss.item() * data.size(0)


    # calculate average losses
    train_loss = train_loss / len(train_loader.sampler)
    valid_loss = valid_loss / len(valid_loader.sampler)

    # print training/validation statistics
    #print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(
    #    epoch, train_loss, valid_loss))



    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f} \ttest accuracy: {:.2f}'.format(
                epoch, train_loss, valid_loss, accuracy))
    #print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)




    writer.add_scalar('Train/Loss', train_loss, epoch)
    writer.add_scalar('Valid/Loss', loss, epoch)

    # save model if validation loss has decreased
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
            valid_loss_min,
            valid_loss))
        torch.save(model.state_dict(), 'model_EEG.pt')
        valid_loss_min = valid_loss




time_total = time.time() - t0
print('Total time: {:4.3f}, average time per epoch: {:4.3f}'.format(time_total, time_total / n_epochs))


# 使用训练好的网络预测
model = AlexNet() #导入网络结构
model.load_state_dict(torch.load('model_EEG.pt')) #导入网络的参数


test_output, test_output1 = model(epochdata_2[:20])
pred_y = torch.max(test_output, 1)[1].data.numpy()

print(pred_y, 'prediction number')
print(test_y[:20].numpy(), 'real number')

test_output2, test_output3 = model(epochdata_2)
pred_y1 = torch.max(test_output2, 1)[1].data.numpy()
accuracy = float((pred_y1 == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))
print('accuracy', accuracy)
